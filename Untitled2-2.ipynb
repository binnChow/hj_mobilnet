{"cells":[{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3975,"status":"ok","timestamp":1657960159824,"user":{"displayName":"dragon w","userId":"04985747203039750146"},"user_tz":-480},"id":"b4CQFjVHaVtw","outputId":"967fec55-24b8-400a-ffce-224fa61857e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1657960162967,"user":{"displayName":"dragon w","userId":"04985747203039750146"},"user_tz":-480},"id":"Xwiw-QYHacJ0"},"outputs":[],"source":["import os\n","os.chdir(\"/content/drive/MyDrive/hj_data/train\")"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"W2ZihS-nY_OG","colab":{"base_uri":"https://localhost:8080/","height":455},"outputId":"42a74a89-dbf2-428d-ae05-2ef3de8ef877","executionInfo":{"status":"error","timestamp":1657960301362,"user_tz":-480,"elapsed":134268,"user":{"displayName":"dragon w","userId":"04985747203039750146"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["create loss dict\n","loss dict created\n","Epoch:1,Loss:1.788143793741862,Accuracy:0.2111913357400722,\n","Epoch:2,Loss:1.7698209948009915,Accuracy:0.26353790613718414,\n","Epoch:3,Loss:1.749735951423645,Accuracy:0.2870036101083033,\n","Epoch:4,Loss:1.7280812131034002,Accuracy:0.3231046931407942,\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-997b0ffbb41d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m501\u001b[0m   \u001b[0;31m# Just for demo, adjust this higher.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-12-997b0ffbb41d>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(model, train_dl, num_epochs)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;31m# Repeat for each batch in the training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m         \u001b[0;31m# Get the input features and target labels, and put them on the GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-997b0ffbb41d>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0mclass_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'classID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#取idx对应行的classID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0maud\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;31m# 有些声音有更高的采样率，或者比大多数声音更少的通道。所以让所有声音都有相同数量的通道和相同的采样率。除非采样速率相同，否则pad_trunc仍然会产生不同长度的数组，即使声音持续时间相同。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0mreaud\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maud\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#标准化采样率\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-997b0ffbb41d>\u001b[0m in \u001b[0;36mopen\u001b[0;34m(audio_file)\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0;31m#audio_file = download_path/'fold1'/'101415-3-0-2.wav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchaudio/backend/sox_io_backend.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filepath, frame_offset, num_frames, normalize, channels_first, format)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     ret = torch.ops.torchaudio.sox_io_load_audio_file(\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     )\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# We save the function ptr as the `op` attribute on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m# OpOverloadPacket to access it here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import pandas as pd \n","from pathlib import Path \n","import math, random \n","import torch \n","import torchaudio \n","from torchaudio import transforms \n","from IPython.display import Audio \n","from torch.utils.data import DataLoader, Dataset, random_split \n","import torch.nn.functional as F \n","from torch.nn import init \n","import torch.nn as nn\n","import numpy as np\n","from sklearn.metrics import f1_score\n","\n","#读取csv文件 \n","download_path = Path.cwd()/'' \n"," \n","# Read metadata file \n","metadata_file = download_path/'data.csv' \n","df = pd.read_csv(metadata_file) \n","df.head() \n"," \n","# Construct file path by concatenating fold and file name \n","df['relative_path'] = '/' + df['fold'].astype(str) + '/' + df['slice_file_name'].astype(str) \n"," \n","# Take relevant columns \n","df = df[['relative_path', 'classID']] \n","df.head()\n","\n","#读取文件中的音频\n","# import math, random \n","# import torch \n","# import torchaudio \n","# from torchaudio import transforms \n","# from IPython.display import Audio \n"," \n","class AudioUtil(): \n","  # ---------------------------- \n","  # Load an audio file. Return the signal as a tensor and the sample rate \n","  # ---------------------------- \n","  @staticmethod \n","  #audio_file = download_path/'fold1'/'101415-3-0-2.wav'\n","  def open(audio_file): \n","    sig, sr = torchaudio.load(audio_file) \n","    return (sig, sr)\n","\n","#转换为立体声\n","# ---------------------------- 未执行\n","  # Convert the given audio to the desired number of channels \n","  # ---------------------------- \n","  @staticmethod \n","  def rechannel(aud, new_channel): \n","    sig, sr = aud \n"," \n","    if (sig.shape[0] == new_channel): \n","      # Nothing to do \n","      return aud \n"," \n","    if (new_channel == 1): \n","      # Convert from stereo to mono by selecting only the first channel \n","      resig = sig[:1, :] \n","    else: \n","      # Convert from mono to stereo by duplicating the first channel \n","      resig = torch.cat([sig, sig]) \n"," \n","    return ((resig, sr))\n","\n","#标准化采样率\n","# ---------------------------- \n","  # Since Resample applies to a single channel, we resample one channel at a time \n","  # ---------------------------- \n","  @staticmethod \n","  def resample(aud, newsr): \n","    sig, sr = aud \n"," \n","    if (sr == newsr): \n","      # Nothing to do \n","      return aud \n"," \n","    num_channels = sig.shape[0] \n","    # Resample first channel \n","    resig = torchaudio.transforms.Resample(sr, newsr)(sig[:1,:]) \n","    if (num_channels > 1): \n","      # Resample the second channel and merge both channels \n","      retwo = torchaudio.transforms.Resample(sr, newsr)(sig[1:,:]) \n","      resig = torch.cat([resig, retwo]) \n"," \n","    return ((resig, newsr))\n","\n","#调整为相同长度\n","# ---------------------------- \n","  # Pad (or truncate) the signal to a fixed length 'max_ms' in milliseconds \n","  # ---------------------------- \n","  @staticmethod \n","  def pad_trunc(aud, max_ms): \n","    sig, sr = aud \n","    num_rows, sig_len = sig.shape \n","    max_len = sr//1000 * max_ms \n"," \n","    if (sig_len > max_len): \n","      # Truncate the signal to the given length \n","      sig = sig[:,:max_len] \n"," \n","    elif (sig_len < max_len): \n","      # Length of padding to add at the beginning and end of the signal \n","      pad_begin_len = random.randint(0, max_len - sig_len) \n","      pad_end_len = max_len - sig_len - pad_begin_len \n"," \n","      # Pad with 0s \n","      pad_begin = torch.zeros((num_rows, pad_begin_len)) \n","      pad_end = torch.zeros((num_rows, pad_end_len)) \n"," \n","      sig = torch.cat((pad_begin, sig, pad_end), 1) \n"," \n","    return (sig, sr)\n","\n","#数据扩充增广（时移）\n","# ---------------------------- \n","  # Shifts the signal to the left or right by some percent. Values at the end \n","  # are 'wrapped around' to the start of the transformed signal. \n","  # ---------------------------- \n","  @staticmethod \n","  def time_shift(aud, shift_limit): \n","    sig,sr = aud \n","    _, sig_len = sig.shape \n","    shift_amt = int(random.random() * shift_limit * sig_len) \n","    return (sig.roll(shift_amt), sr)\n","\n","#梅尔谱图\n","# ---------------------------- \n","  # Generate a Spectrogram \n","  # ---------------------------- \n","  @staticmethod \n","  def spectro_gram(aud, n_mels=64, n_fft=1024, hop_len=None): \n","    sig,sr = aud \n","    top_db = 80 \n"," \n","    # spec has shape [channel, n_mels, time], where channel is mono, stereo etc \n","    spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig) \n"," \n","    # Convert to decibels \n","    spec = transforms.AmplitudeToDB(top_db=top_db)(spec) \n","    return (spec)\n","\n","#数据扩充：时间和频率屏蔽\n","# ---------------------------- \n","  # Augment the Spectrogram by masking out some sections of it in both the frequency \n","  # dimension (ie. horizontal bars) and the time dimension (vertical bars) to prevent \n","  # overfitting and to help the model generalise better. The masked sections are \n","  # replaced with the mean value. \n","  # ---------------------------- \n","  @staticmethod \n","  def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1): \n","    _, n_mels, n_steps = spec.shape \n","    mask_value = spec.mean() \n","    aug_spec = spec \n"," \n","    freq_mask_param = max_mask_pct * n_mels \n","    for _ in range(n_freq_masks): \n","      aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value) \n"," \n","    time_mask_param = max_mask_pct * n_steps \n","    for _ in range(n_time_masks): \n","      aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value) \n"," \n","    return aug_spec\n","\n","#自定义数据加载器\n","# from torch.utils.data import DataLoader, Dataset, random_split \n","# import torchaudio \n"," \n","# ---------------------------- \n","# Sound Dataset \n","# ---------------------------- \n","# SoundDS：MyDataset类\n","class SoundDS(Dataset): \n","  def __init__(self, df, data_path): \n","    self.df = df #df为csv文件\n","    self.data_path = str(data_path) \n","    self.duration = 6000 \n","    self.sr = 22050 #采样率\n","    self.channel = 2 #通道数\n","    self.shift_pct = 0.4        \n"," \n","  # ---------------------------- \n","  # Number of items in dataset \n","  # ---------------------------- \n","  def __len__(self): \n","    return len(self.df)     \n"," \n","  # ---------------------------- \n","  # Get i'th item in dataset \n","  # ---------------------------- \n","  def __getitem__(self, idx): \n","    # Absolute file path of the audio file - concatenate the audio directory with \n","    # the relative path \n","    audio_file = self.data_path + self.df.loc[idx, 'relative_path']  #.loc:取idx对应行的所有数据，.loc[idx, 'relative_path']:取idx对应行的relative_path\n","    # Get the Class ID \n","    class_id = self.df.loc[idx, 'classID'] #取idx对应行的classID\n"," \n","    aud = AudioUtil.open(audio_file) \n","    # 有些声音有更高的采样率，或者比大多数声音更少的通道。所以让所有声音都有相同数量的通道和相同的采样率。除非采样速率相同，否则pad_trunc仍然会产生不同长度的数组，即使声音持续时间相同。\n","    reaud = AudioUtil.resample(aud, self.sr) #标准化采样率\n","    rechan = AudioUtil.rechannel(reaud, self.channel) #转换为立体声，统一为两个声道\n"," \n","    dur_aud = AudioUtil.pad_trunc(rechan, self.duration) #调整为相同长度\n","    shift_aud = AudioUtil.time_shift(dur_aud, self.shift_pct) #时移\n","    sgram = AudioUtil.spectro_gram(shift_aud, n_mels=64, n_fft=1024, hop_len=None) #转换为mel谱图\n","    aug_sgram = AudioUtil.spectro_augment(sgram, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2) #时间和频率屏蔽\n"," \n","    return aug_sgram, class_id\n","\n","#使用数据加载器准备一批数据\n","from torch.utils.data import random_split \n"," \n","myds = SoundDS(df,download_path) \n"," \n","# Random split of 90:10 between training and validation \n","num_items = len(myds) \n","num_train = round(num_items * 0.9) \n","num_val = num_items - num_train \n","train_ds, val_ds = random_split(myds, [num_train, num_val]) \n"," \n","# Create training and validation data loaders \n","train_dl = torch.utils.data.DataLoader(train_ds, batch_size=64, shuffle=True) \n","val_dl = torch.utils.data.DataLoader(val_ds, batch_size=64, shuffle=False)\n","\n","#建立模型\n","# import torch.nn.functional as F \n","# from torch.nn import init \n"," \n","# ---------------------------- \n","# Audio Classification Model \n","# ---------------------------- \n","class AudioClassifier (nn.Module): \n","    # ---------------------------- \n","    # Build the model architecture \n","    # ---------------------------- \n","    def __init__(self): \n","        super().__init__() \n","        conv_layers = [] \n"," \n","        # First Convolution Block with Relu and Batch Norm. Use Kaiming Initialization \n","        self.conv1 = nn.Conv2d(2, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2)) #in_channels=2,out_channels=8\n","        self.relu1 = nn.ReLU() \n","        self.bn1 = nn.BatchNorm2d(8) \n","        init.kaiming_normal_(self.conv1.weight, a=0.1) #a-此层之后使用的整流器的负斜率(仅与 'leaky_relu' 一起使用)\n","        self.conv1.bias.data.zero_() \n","        conv_layers += [self.conv1, self.relu1, self.bn1] \n"," \n","        # Second Convolution Block \n","        self.conv2 = nn.Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)) \n","        self.relu2 = nn.ReLU() \n","        self.bn2 = nn.BatchNorm2d(16) \n","        init.kaiming_normal_(self.conv2.weight, a=0.1) \n","        self.conv2.bias.data.zero_() \n","        conv_layers += [self.conv2, self.relu2, self.bn2] \n"," \n","        # third Convolution Block \n","        self.conv3 = nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)) \n","        self.relu3 = nn.ReLU() \n","        self.bn3 = nn.BatchNorm2d(32) \n","        init.kaiming_normal_(self.conv3.weight, a=0.1) \n","        self.conv3.bias.data.zero_() \n","        conv_layers += [self.conv3, self.relu3, self.bn3] \n"," \n","        # fourth Convolution Block \n","        self.conv4 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)) \n","        self.relu4 = nn.ReLU() \n","        self.bn4 = nn.BatchNorm2d(64) \n","        init.kaiming_normal_(self.conv4.weight, a=0.1) \n","        self.conv4.bias.data.zero_() \n","        conv_layers += [self.conv4, self.relu4, self.bn4] \n"," \n","        # Linear Classifier \n","        self.ap = nn.AdaptiveAvgPool2d(output_size=1) \n","        self.lin = nn.Linear(in_features=64, out_features=6) \n"," \n","        # Wrap the Convolutional Blocks 打包卷积块\n","        self.conv = nn.Sequential(*conv_layers) \n"," \n","    # ---------------------------- \n","    # Forward pass computations \n","    # ---------------------------- \n","    def forward(self, x): \n","        # Run the convolutional blocks \n","        x = self.conv(x) \n"," \n","        # Adaptive pool and flatten for input to linear layer \n","        x = self.ap(x) \n","        x = x.view(x.shape[0], -1) #=reshape 重新定义矩阵形状，-1代表动态调整这个维度上的元素个数，以保证元素的总数不变\n"," \n","        # Linear layer \n","        x = self.lin(x) \n"," \n","        # Final output \n","        return x \n"," \n","# Create the model and put it on the GPU if available \n","myModel = AudioClassifier() \n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n","myModel = myModel.to(device) \n","# Check that it is on Cuda \n","next(myModel.parameters()).device\n","\n","#训练\n","# ---------------------------- \n","# Training Loop \n","# ---------------------------- \n","def training(model, train_dl, num_epochs): \n","  # Loss Function, Optimizer and Scheduler \n","  criterion = nn.CrossEntropyLoss() \n","  optimizer = torch.optim.Adam(model.parameters(),lr=0.001) \n","  scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001, \n","                                                steps_per_epoch=int(len(train_dl)), \n","                                                epochs=num_epochs, \n","                                                anneal_strategy='linear') #退火策略，'cos'和'liner'分别表示余弦退火和线性退火\n"," \n","  expdir = Path.cwd()/'/content/drive/MyDrive/hj_data/experiments'\n","  version = 'v2'\n","  logfilepath = expdir / version / 'logs_{}.txt'.format(version)\n","  logfilepath_eval = expdir / version / 'logs_eval_{}.txt'.format(version)\n","  model_savedir = expdir / version \n","  def init_logger(self):\n","        self.logFileName = str(self.logfilepath)\n","        if self.logfilepath.exists == True:\n","            self.logfilepath.exists.unlink()  ## 删除已经存在的log文件 (方便重启实验)\n","        if self.logfilepath_eval.exists == True:\n","            self.logfilepath_eval.exists.unlink()  ## 删除已经存在的log文件 (方便重启实验)\n","        self.logFileName_eval = str(self.logfilepath_eval)\n","\n","        ## 存储training log文件\n","        with open(self.logFileName, 'a', encoding='utf-8') as wf:\n","            # #将参数类中的所有参数写入log\n","            # for k, v in self.hp.__dict__.items():\n","            #     wf.write(\"{} : {}\\n\".format(k, v))\n","            # wf.write('-' * 50 + \"Experiment & Hparams Created\" + \"-\" * 50 + \"\\n\")\n","            wf.write(\"*\" * 100 + \"\\n\")\n","            wf.close()\n","\n","    ## 该方法将一个字典  ，按kv的顺序，写入一行到 log.txt\n","  def write_line2log(log_dict: dict, filedir, isprint: True):\n","      strp = ''\n","      with open(filedir, 'a', encoding='utf-8') as f:\n","          for key, value in log_dict.items():\n","              witem = '{}'.format(key) + ':{},'.format(value)\n","              strp += witem\n","          f.write(strp)\n","          #f.write('当前进程的内存使用：%.4f GB' % (psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024 / 1024))\n","          f.write('\\n')\n","      if isprint:\n","          print(strp)\n","      pass\n","\n","  def print_network(model, name):\n","      \"\"\"Print out the network information.\"\"\"\n","      num_params = 0\n","      for p in model.parameters():\n","          num_params += p.numel()\n","      print(\"Model {},the number of parameters: {}\".format(name, num_params))\n","\n","  #保存模型\n","  def save_model(i):\n","      pdict = {\"model\":model.state_dict(),\n","                }\n","      path = model_savedir / \"{:04}.pth\".format(i)\n","      torch.save(pdict, str(path))\n","      print(\"---------------- model saved ------------------- \")\n","  \n","  def micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on binary arrays.\n","\n","    Args:\n","        preds (list of lists of ints): Predictions.\n","        truths (list of lists of ints): Ground truths.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    # Micro : aggregating over all instances\n","    # device = torch.device('cpu')\n","    # # preds = preds.to(device)\n","    # # truths = preds.to(device)\n","    # preds.cpu()\n","    # truths.cpu()\n","    preds = np.concatenate(preds)\n","    truths = np.concatenate(truths)\n","    return f1_score(truths, preds,average='micro')\n","\n","  #测试\n","  def test_acc (model, val_dl):\n","    correct_prediction = 0\n","    total_prediction = 0\n","\n","    truths = []\n","    preds = []\n","    # Disable gradient updates\n","    with torch.no_grad():\n","      for data in val_dl:\n","        # Get the input features and target labels, and put them on the GPU\n","        inputs, labels = data[0].to(device), data[1].to(device)\n","\n","        # Normalize the inputs\n","        inputs_m, inputs_s = inputs.mean(), inputs.std()\n","        inputs = (inputs - inputs_m) / inputs_s\n","\n","        # Get predictions\n","        outputs = model(inputs)\n","\n","        # Get the predicted class with the highest score\n","        _, prediction = torch.max(outputs,1)\n","        # Count of predictions that matched the target label\n","        correct_prediction += (prediction == labels).sum().item()\n","        total_prediction += prediction.shape[0]\n","        print(f'labes: {labels},preds: {prediction}')\n","        # state = torch.device('cpu')\n","        # labels = labels.to(device)\n","        # prediction = prediction.to(device)\n","        labels = labels.cpu()\n","        prediction = prediction.cpu()\n","        print(f'labes: {labels},preds: {prediction}')\n","        truths.append(labels)\n","        preds.append(prediction)\n","\n","    \n","    acc = correct_prediction/total_prediction\n","    f1 = micro_f1(truths,preds)\n","    losse_curves  = {\"eval_step--\":\"\",\n","                    \"Epoch\":epoch,\n","                    \"Accuracy\":acc,\n","                    \"Micro_f1\":f1,\n","                    \"Total items\":total_prediction}\n","    write_line2log(losse_curves, logfilepath_eval, isprint=True)\n","\n","\n","  # Repeat for each epoch \n","  for epoch in range(1,num_epochs): \n","    running_loss = 0.0 \n","    correct_prediction = 0 \n","    total_prediction = 0 \n"," \n","    # Repeat for each batch in the training set \n","    for i, data in enumerate(train_dl): \n","        # Get the input features and target labels, and put them on the GPU \n","        inputs, labels = data[0].to(device), data[1].to(device) \n"," \n","        # Normalize the inputs \n","        inputs_m, inputs_s = inputs.mean(), inputs.std() #标准差\n","        inputs = (inputs - inputs_m) / inputs_s \n"," \n","        # Zero the parameter gradients \n","        optimizer.zero_grad() \n"," \n","        # forward + backward + optimize \n","        outputs = model(inputs) \n","        loss = criterion(outputs, labels) \n","        loss.backward() \n","        optimizer.step() \n","        scheduler.step() \n"," \n","        # Keep stats for Loss and Accuracy \n","        running_loss += loss.item() \n"," \n","        # Get the predicted class with the highest score \n","        _, prediction = torch.max(outputs,1) \n","        # Count of predictions that matched the target label \n","        correct_prediction += (prediction == labels).sum().item() \n","        total_prediction += prediction.shape[0] \n"," \n","        # if i % 10 == 0:    # print every 10 mini-batches \n","        #     print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 10)) \n"," \n","    # Print stats at the end of the epoch \n","    num_batches = len(train_dl)\n","    avg_loss = running_loss / num_batches \n","    acc = correct_prediction/total_prediction \n","    losse_curves  = {\"Epoch\":epoch,\n","                            \"Loss\":avg_loss,\n","                             \"Accuracy\":acc,\n","                             }\n","    if epoch == 1:\n","      print(\"create loss dict\")\n","      loss_log_dict = {}\n","      for k, v in losse_curves.items():\n","        loss_log_dict[k] = []\n","      print(\"loss dict created\")\n","    \n","    for k, v in loss_log_dict.items():\n","      loss_log_dict[k].append(losse_curves[k])  # 把每batch的loss数据加入到 loss curves中\n","    write_line2log(losse_curves, logfilepath, isprint=True)\n","\n","    ## 模型保存\n","    if epoch % 50 == 0:\n","      test_acc(myModel,val_dl)\n","      save_model(epoch)\n","    # print(f'Epoch: {epoch}, Loss: {avg_loss:.2f}, Accuracy: {acc:.2f}') \n"," \n","  print('Finished Training') \n"," \n","num_epochs=501   # Just for demo, adjust this higher. \n","training(myModel, train_dl, num_epochs)"]},{"cell_type":"markdown","metadata":{"id":"lAB-Dr3oe308"},"source":["# **推理**"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9666,"status":"ok","timestamp":1657961465015,"user":{"displayName":"dragon w","userId":"04985747203039750146"},"user_tz":-480},"id":"F0ifLiFae1Sh","outputId":"7d0ec50d-c4ce-40d4-9297-d2aaae16fd29"},"outputs":[{"output_type":"stream","name":"stdout","text":["outputs:tensor([[ 0.2391, -3.1450,  2.9618,  1.0354, -1.4945, -0.1898],\n","        [ 2.2042, -0.5069, -2.3192, -1.3497,  2.6031, -0.2072],\n","        [ 2.5407,  2.0187, -3.2856, -3.8050, -0.8271,  3.1465],\n","        ...,\n","        [-3.0530,  2.7428,  0.8797,  0.8470,  1.0830, -1.1640],\n","        [ 0.7300, -0.2620, -0.0184,  0.1264, -0.1903,  0.1435],\n","        [ 1.1884, -1.7355,  1.3990,  0.6377, -1.8540, -1.0835]])\n","labes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0]),preds: tensor([2, 4, 5, 5, 3, 3, 2, 1, 1, 4, 3, 5, 5, 0, 1, 3, 0, 3, 4, 0, 2, 4, 4, 1,\n","        3, 5, 2, 4, 5, 1, 0, 1, 1, 2, 0, 0, 5, 0, 4, 2, 4, 1, 4, 2, 1, 2, 5, 0,\n","        3, 0, 1, 4, 0, 3, 1, 5, 2, 5, 4, 1, 2, 1, 5, 4, 2, 5, 2, 2, 4, 1, 5, 2,\n","        5, 0, 4, 2, 1, 4, 5, 0, 0, 3, 3, 1, 4, 5, 5, 2, 0, 2, 0, 3, 3, 3, 5, 4,\n","        0, 5, 0, 1, 3, 0, 3, 5, 0, 2, 4, 4, 5, 3, 2, 0, 1, 3, 2, 4, 5, 5, 4, 0,\n","        0, 3, 1, 3, 5, 0, 1, 2, 2, 5, 3, 2, 0, 4, 3, 4, 4, 0, 0, 5, 5, 2, 0, 1,\n","        0, 5, 3, 4, 0, 5, 3, 1, 2, 2, 2, 5, 2, 3, 2, 0, 5, 3, 1, 1, 2, 3, 5, 5,\n","        1, 2, 2, 4, 1, 1, 2, 3, 1, 5, 2, 5, 0, 2, 0, 2, 0, 3, 0, 5, 3, 0, 3, 4,\n","        5, 0, 0, 5, 1, 0, 2])\n"]}],"source":["import csv #调用数据保存文件\n","import pandas as pd #用于数据输出\n","from pathlib import Path \n","\n","#读取csv文件 \n","test_path = Path.cwd()/'../test' \n","#model_savedir = '/content/drive/MyDrive/hj_data/experiments/v0' \n"," \n","# Read metadata file \n","testdata_file = test_path/'test.csv' \n","tf = pd.read_csv(testdata_file) \n","tf.head() \n"," \n","# Construct file path by concatenating fold and file name \n","tf['relative_path'] = '/' + tf['slice_file_name'].astype(str) \n"," \n","# Take relevant columns \n","tf = tf[['relative_path', 'classID']] \n","tf.head()\n","\n","\n","#加载测试数据\n","testds = SoundDS(tf,test_path) \n","\n","# Create test data loaders \n","test_dl = torch.utils.data.DataLoader(testds, batch_size=256, shuffle=False) \n","\n","# def __getitem__(self, idx):\n","#   id = self.tf['slice_file_name'].astype(str)\n","\n","# ---------------------------- \n","# Inference \n","# ---------------------------- \n","def inference (model, test_dl): \n","  correct_prediction = 0 \n","  total_prediction = 0 \n","\n","  # Disable gradient updates \n","  with torch.no_grad(): \n","    list_classid = []\n","    list1 = []\n","    id = 0\n","    for data in test_dl: \n","      id = id + 1\n","      # Get the input features and target labels, and put them on the GPU \n","      inputs, labels = data[0].to(device), data[1].to(device) \n"," \n","      # Normalize the inputs \n","      inputs_m, inputs_s = inputs.mean(), inputs.std() \n","      inputs = (inputs - inputs_m) / inputs_s \n"," \n","      # Get predictions \n","      outputs = model(inputs) \n","      print(f'outputs:{outputs}')\n","  \n","      # Get the predicted class with the highest score \n","      _, prediction = torch.max(outputs,1) \n","      print(f'labes: {labels},preds: {prediction}')\n","      # ClassId.append(prediction + 1)\n","      list_classid.append(prediction.numpy() + 1)\n","      list_classid = np.concatenate(list_classid)\n","      # Count of predictions that matched the target label \n","      #correct_prediction += (prediction == labels).sum().item() \n","      #total_prediction += prediction.shape[0] \n","      list1.append(id)\n","      list=[]\n","      list.append(list1)\n","      list.append(list_classid)\n","      #print(list)\n","    column=['label'] #列表头名称\n","    test=pd.DataFrame(zip(list_classid),columns=['label'])#将数据放进表格\n","    test.to_csv('result.csv') #数据存入csv,存储位置及文件名称\n","      # print(f'{data[0]}, ClassId: {ClassId}')\n","\n","\n","\n"," \n","  #acc = correct_prediction/total_prediction \n","  #print(f'Accuracy: {acc:.2f}, Total items: {total_prediction}') \n"," \n","# Run inference on trained model with the validation set\n","i = 150 #用于指定加载哪个模型\n","#model_path = model_savedir / \"{:04}.pth\".format(i)\n","model_path = '/content/drive/MyDrive/hj_data/experiments/v1/0100.pth'\n","model = myModel\n","state = torch.load(model_path,map_location=torch.device('cpu'))\n","model.load_state_dict(state['model'])\n","inference(model, test_dl)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Untitled2.ipynb","provenance":[],"authorship_tag":"ABX9TyP05TJzHBUkhJIYUMkot2AT"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}