{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31630,"status":"ok","timestamp":1657945264596,"user":{"displayName":"dragon w","userId":"04985747203039750146"},"user_tz":-480},"id":"b4CQFjVHaVtw","outputId":"70e33ff4-20e8-43f8-ba3a-414c3c984f99"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":990,"status":"ok","timestamp":1657945268241,"user":{"displayName":"dragon w","userId":"04985747203039750146"},"user_tz":-480},"id":"Xwiw-QYHacJ0"},"outputs":[],"source":["import os\n","os.chdir(\"/content/drive/MyDrive/hj_data/train\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W2ZihS-nY_OG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"be620e8c-91fe-4815-e8d5-92937de114cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["create loss dict\n","loss dict created\n","Epoch:1,Loss:1.7692620356877644,Accuracy:0.2111913357400722,\n","Epoch:2,Loss:1.7481220960617065,Accuracy:0.26895306859205775,\n","Epoch:3,Loss:1.729433496793111,Accuracy:0.2527075812274368,\n","Epoch:4,Loss:1.708642601966858,Accuracy:0.26534296028880866,\n","Epoch:5,Loss:1.6821375687917073,Accuracy:0.3231046931407942,\n","Epoch:6,Loss:1.65176522731781,Accuracy:0.34296028880866425,\n","Epoch:7,Loss:1.6347358491685655,Accuracy:0.34115523465703973,\n","Epoch:8,Loss:1.616469489203559,Accuracy:0.351985559566787,\n","Epoch:9,Loss:1.5883971982532077,Accuracy:0.37906137184115524,\n","Epoch:10,Loss:1.5659896002875433,Accuracy:0.3916967509025271,\n","Epoch:11,Loss:1.5445939302444458,Accuracy:0.41335740072202165,\n","Epoch:12,Loss:1.5255808432896931,Accuracy:0.44223826714801445,\n","Epoch:13,Loss:1.495904525121053,Accuracy:0.43501805054151627,\n","Epoch:14,Loss:1.474489410718282,Accuracy:0.4602888086642599,\n","Epoch:15,Loss:1.461493624581231,Accuracy:0.4584837545126354,\n","Epoch:16,Loss:1.4376066393322415,Accuracy:0.4548736462093863,\n","Epoch:17,Loss:1.4102751546435885,Accuracy:0.48194945848375453,\n","Epoch:18,Loss:1.385056323475308,Accuracy:0.5036101083032491,\n","Epoch:19,Loss:1.3541243606143527,Accuracy:0.5144404332129964,\n","Epoch:20,Loss:1.3310325543085735,Accuracy:0.5288808664259927,\n","Epoch:21,Loss:1.3109565046098497,Accuracy:0.5433212996389891,\n","Epoch:22,Loss:1.2878187365002103,Accuracy:0.5288808664259927,\n","Epoch:23,Loss:1.2737002505196466,Accuracy:0.5415162454873647,\n","Epoch:24,Loss:1.2316775586869981,Accuracy:0.5451263537906137,\n","Epoch:25,Loss:1.2283869451946683,Accuracy:0.572202166064982,\n","Epoch:26,Loss:1.2305003537072077,Accuracy:0.555956678700361,\n","Epoch:27,Loss:1.1868519518110487,Accuracy:0.5740072202166066,\n","Epoch:28,Loss:1.1778087218602498,Accuracy:0.5667870036101083,\n","Epoch:29,Loss:1.1544408135943942,Accuracy:0.5938628158844765,\n","Epoch:30,Loss:1.148523939980401,Accuracy:0.5956678700361011,\n","Epoch:31,Loss:1.1204635567135282,Accuracy:0.592057761732852,\n","Epoch:32,Loss:1.1059407922956679,Accuracy:0.6137184115523465,\n","Epoch:33,Loss:1.0922041866514418,Accuracy:0.6028880866425993,\n","Epoch:34,Loss:1.0644345084826152,Accuracy:0.6245487364620939,\n","Epoch:35,Loss:1.0460289319356282,Accuracy:0.6119133574007221,\n","Epoch:36,Loss:1.0434959597057767,Accuracy:0.6245487364620939,\n","Epoch:37,Loss:1.0117328365643818,Accuracy:0.6191335740072202,\n","Epoch:38,Loss:1.013890849219428,Accuracy:0.6389891696750902,\n","Epoch:39,Loss:0.9910634358723959,Accuracy:0.6245487364620939,\n","Epoch:40,Loss:0.9730020099216037,Accuracy:0.6353790613718412,\n","Epoch:41,Loss:0.9679843584696451,Accuracy:0.6353790613718412,\n","Epoch:42,Loss:0.9456438091066148,Accuracy:0.6552346570397112,\n","Epoch:43,Loss:0.9445390767521329,Accuracy:0.6462093862815884,\n","Epoch:44,Loss:0.9423002004623413,Accuracy:0.6425992779783394,\n","Epoch:45,Loss:0.9259800910949707,Accuracy:0.6516245487364621,\n","Epoch:46,Loss:0.8799385759565566,Accuracy:0.6642599277978339,\n","Epoch:47,Loss:0.8836445079909431,Accuracy:0.6787003610108303,\n","Epoch:48,Loss:0.8584635323948331,Accuracy:0.6714801444043321,\n","Epoch:49,Loss:0.8349930776490105,Accuracy:0.7129963898916968,\n","Epoch:50,Loss:0.8202455639839172,Accuracy:0.7129963898916968,\n","labes: tensor([3, 2, 1, 4, 0, 2, 1, 1, 3, 3, 1, 4, 5, 2, 1, 3, 1, 5, 4, 0, 3, 0, 3, 4,\n","        0, 0, 5, 1, 5, 0, 1, 3, 4, 3, 0, 2, 5, 0, 4, 3, 5, 2, 3, 2, 3, 0, 1, 5,\n","        2, 3, 2, 0, 5, 4, 0, 5, 3, 4, 3, 4, 3, 4], device='cuda:0'),preds: tensor([2, 3, 1, 4, 0, 2, 1, 1, 3, 3, 1, 4, 5, 4, 1, 3, 1, 5, 4, 2, 2, 0, 3, 0,\n","        0, 0, 4, 1, 0, 0, 1, 2, 4, 2, 5, 2, 5, 5, 4, 3, 5, 2, 3, 4, 3, 4, 5, 0,\n","        2, 3, 4, 0, 5, 4, 3, 0, 2, 4, 2, 4, 3, 4], device='cuda:0')\n","labes: tensor([3, 2, 1, 4, 0, 2, 1, 1, 3, 3, 1, 4, 5, 2, 1, 3, 1, 5, 4, 0, 3, 0, 3, 4,\n","        0, 0, 5, 1, 5, 0, 1, 3, 4, 3, 0, 2, 5, 0, 4, 3, 5, 2, 3, 2, 3, 0, 1, 5,\n","        2, 3, 2, 0, 5, 4, 0, 5, 3, 4, 3, 4, 3, 4]),preds: tensor([2, 3, 1, 4, 0, 2, 1, 1, 3, 3, 1, 4, 5, 4, 1, 3, 1, 5, 4, 2, 2, 0, 3, 0,\n","        0, 0, 4, 1, 0, 0, 1, 2, 4, 2, 5, 2, 5, 5, 4, 3, 5, 2, 3, 4, 3, 4, 5, 0,\n","        2, 3, 4, 0, 5, 4, 3, 0, 2, 4, 2, 4, 3, 4])\n","eval_step--:,Epoch:50,Accuracy:0.6612903225806451,Micro_f1:0.6612903225806451,Total items:62,\n","---------------- model saved ------------------- \n","Epoch:51,Loss:0.8372850683000352,Accuracy:0.6660649819494585,\n","Epoch:52,Loss:0.8148130045996772,Accuracy:0.7057761732851986,\n","Epoch:53,Loss:0.8152339590920342,Accuracy:0.7166064981949458,\n","Epoch:54,Loss:0.7811203598976135,Accuracy:0.7093862815884476,\n","Epoch:55,Loss:0.7546463873651292,Accuracy:0.7364620938628159,\n","Epoch:56,Loss:0.759429587258233,Accuracy:0.7292418772563177,\n","Epoch:57,Loss:0.7525187465879652,Accuracy:0.7274368231046932,\n","Epoch:58,Loss:0.7161010901133219,Accuracy:0.7454873646209387,\n","Epoch:59,Loss:0.700625995794932,Accuracy:0.759927797833935,\n","Epoch:60,Loss:0.7191350592507256,Accuracy:0.7310469314079422,\n","Epoch:61,Loss:0.6958393189642165,Accuracy:0.7635379061371841,\n","Epoch:62,Loss:0.7037693328327603,Accuracy:0.7617328519855595,\n","Epoch:63,Loss:0.6728559401300218,Accuracy:0.776173285198556,\n","Epoch:64,Loss:0.6740870277086893,Accuracy:0.7779783393501805,\n","Epoch:65,Loss:0.6665902932484945,Accuracy:0.776173285198556,\n","Epoch:66,Loss:0.6473474767473009,Accuracy:0.7635379061371841,\n","Epoch:67,Loss:0.6590808033943176,Accuracy:0.7563176895306859,\n","Epoch:68,Loss:0.621650238831838,Accuracy:0.8068592057761733,\n","Epoch:69,Loss:0.6071349051263597,Accuracy:0.7870036101083032,\n","Epoch:70,Loss:0.5973605646027459,Accuracy:0.7996389891696751,\n","Epoch:71,Loss:0.6400245626767477,Accuracy:0.7635379061371841,\n","Epoch:72,Loss:0.5899726351102194,Accuracy:0.7996389891696751,\n","Epoch:73,Loss:0.5796819263034396,Accuracy:0.7906137184115524,\n","Epoch:74,Loss:0.5973686344093747,Accuracy:0.7996389891696751,\n","Epoch:75,Loss:0.5930148594909244,Accuracy:0.7996389891696751,\n","Epoch:76,Loss:0.5624953707059225,Accuracy:0.8212996389891697,\n","Epoch:77,Loss:0.5485885573758019,Accuracy:0.8212996389891697,\n","Epoch:78,Loss:0.5523802936077118,Accuracy:0.8050541516245487,\n","Epoch:79,Loss:0.550574905342526,Accuracy:0.8140794223826715,\n","Epoch:80,Loss:0.5386889676253,Accuracy:0.8086642599277978,\n","Epoch:81,Loss:0.5345349841647677,Accuracy:0.8014440433212996,\n","Epoch:82,Loss:0.4884671171506246,Accuracy:0.8447653429602888,\n","Epoch:83,Loss:0.5039252903726366,Accuracy:0.8357400722021661,\n","Epoch:84,Loss:0.5156752996974521,Accuracy:0.8176895306859205,\n","Epoch:85,Loss:0.46348962518903947,Accuracy:0.851985559566787,\n","Epoch:86,Loss:0.48060207565625507,Accuracy:0.8465703971119134,\n","Epoch:87,Loss:0.47658056020736694,Accuracy:0.8465703971119134,\n","Epoch:88,Loss:0.47549410661061603,Accuracy:0.8267148014440433,\n","Epoch:89,Loss:0.47188501556714374,Accuracy:0.8483754512635379,\n","Epoch:90,Loss:0.4605751434961955,Accuracy:0.8321299638989169,\n","Epoch:91,Loss:0.4604940911134084,Accuracy:0.851985559566787,\n","Epoch:92,Loss:0.4211113221115536,Accuracy:0.8664259927797834,\n","Epoch:93,Loss:0.4355827007028792,Accuracy:0.8736462093862816,\n","Epoch:94,Loss:0.4132409691810608,Accuracy:0.8700361010830325,\n","Epoch:95,Loss:0.4248478081491258,Accuracy:0.868231046931408,\n","Epoch:96,Loss:0.43478289246559143,Accuracy:0.8537906137184116,\n","Epoch:97,Loss:0.3798646032810211,Accuracy:0.8862815884476535,\n","Epoch:98,Loss:0.38736018869611955,Accuracy:0.8916967509025271,\n","Epoch:99,Loss:0.3973499404059516,Accuracy:0.8808664259927798,\n","Epoch:100,Loss:0.3965680069393582,Accuracy:0.868231046931408,\n","labes: tensor([3, 2, 1, 4, 0, 2, 1, 1, 3, 3, 1, 4, 5, 2, 1, 3, 1, 5, 4, 0, 3, 0, 3, 4,\n","        0, 0, 5, 1, 5, 0, 1, 3, 4, 3, 0, 2, 5, 0, 4, 3, 5, 2, 3, 2, 3, 0, 1, 5,\n","        2, 3, 2, 0, 5, 4, 0, 5, 3, 4, 3, 4, 3, 4], device='cuda:0'),preds: tensor([2, 2, 1, 0, 0, 2, 1, 1, 3, 3, 1, 4, 5, 2, 1, 2, 1, 5, 4, 0, 2, 5, 3, 4,\n","        0, 4, 4, 1, 0, 0, 1, 3, 4, 2, 0, 2, 5, 1, 4, 3, 5, 2, 3, 4, 3, 4, 5, 5,\n","        2, 2, 4, 0, 5, 4, 0, 0, 0, 4, 3, 4, 3, 4], device='cuda:0')\n","labes: tensor([3, 2, 1, 4, 0, 2, 1, 1, 3, 3, 1, 4, 5, 2, 1, 3, 1, 5, 4, 0, 3, 0, 3, 4,\n","        0, 0, 5, 1, 5, 0, 1, 3, 4, 3, 0, 2, 5, 0, 4, 3, 5, 2, 3, 2, 3, 0, 1, 5,\n","        2, 3, 2, 0, 5, 4, 0, 5, 3, 4, 3, 4, 3, 4]),preds: tensor([2, 2, 1, 0, 0, 2, 1, 1, 3, 3, 1, 4, 5, 2, 1, 2, 1, 5, 4, 0, 2, 5, 3, 4,\n","        0, 4, 4, 1, 0, 0, 1, 3, 4, 2, 0, 2, 5, 1, 4, 3, 5, 2, 3, 4, 3, 4, 5, 5,\n","        2, 2, 4, 0, 5, 4, 0, 0, 0, 4, 3, 4, 3, 4])\n","eval_step--:,Epoch:100,Accuracy:0.7258064516129032,Micro_f1:0.7258064516129032,Total items:62,\n","---------------- model saved ------------------- \n","Epoch:101,Loss:0.3793552882141537,Accuracy:0.8646209386281588,\n","Epoch:102,Loss:0.37860556774669224,Accuracy:0.8916967509025271,\n","Epoch:103,Loss:0.42869776487350464,Accuracy:0.8465703971119134,\n","Epoch:104,Loss:0.3768498930666182,Accuracy:0.8844765342960289,\n","Epoch:105,Loss:0.40391355256239575,Accuracy:0.8772563176895307,\n","Epoch:106,Loss:0.36744532320234513,Accuracy:0.8826714801444043,\n","Epoch:107,Loss:0.35650842057334053,Accuracy:0.8826714801444043,\n","Epoch:108,Loss:0.3866145958503087,Accuracy:0.8808664259927798,\n","Epoch:109,Loss:0.34566954606109196,Accuracy:0.8898916967509025,\n","Epoch:110,Loss:0.32838673724068534,Accuracy:0.8953068592057761,\n","Epoch:111,Loss:0.36408517758051556,Accuracy:0.8862815884476535,\n","Epoch:112,Loss:0.32727790541119045,Accuracy:0.9007220216606499,\n","Epoch:113,Loss:0.3662504288885329,Accuracy:0.871841155234657,\n","Epoch:114,Loss:0.33841361933284336,Accuracy:0.8862815884476535,\n","Epoch:115,Loss:0.3276997142367893,Accuracy:0.8862815884476535,\n","Epoch:116,Loss:0.33810318013032276,Accuracy:0.9025270758122743,\n","Epoch:117,Loss:0.3255416767464744,Accuracy:0.9097472924187726,\n","Epoch:118,Loss:0.2988622205124961,Accuracy:0.9133574007220217,\n","Epoch:119,Loss:0.3300141592820485,Accuracy:0.8898916967509025,\n"]}],"source":["import pandas as pd \n","from pathlib import Path \n","import math, random \n","import torch \n","import torchaudio \n","from torchaudio import transforms \n","from IPython.display import Audio \n","from torch.utils.data import DataLoader, Dataset, random_split \n","import torch.nn.functional as F \n","from torch.nn import init \n","import torch.nn as nn\n","import numpy as np\n","from sklearn.metrics import f1_score\n","\n","#读取csv文件 \n","download_path = Path.cwd()/'' \n"," \n","# Read metadata file \n","metadata_file = download_path/'data.csv' \n","df = pd.read_csv(metadata_file) \n","df.head() \n"," \n","# Construct file path by concatenating fold and file name \n","df['relative_path'] = '/' + df['fold'].astype(str) + '/' + df['slice_file_name'].astype(str) \n"," \n","# Take relevant columns \n","df = df[['relative_path', 'classID']] \n","df.head()\n","\n","#读取文件中的音频\n","# import math, random \n","# import torch \n","# import torchaudio \n","# from torchaudio import transforms \n","# from IPython.display import Audio \n"," \n","class AudioUtil(): \n","  # ---------------------------- \n","  # Load an audio file. Return the signal as a tensor and the sample rate \n","  # ---------------------------- \n","  @staticmethod \n","  #audio_file = download_path/'fold1'/'101415-3-0-2.wav'\n","  def open(audio_file): \n","    sig, sr = torchaudio.load(audio_file) \n","    return (sig, sr)\n","\n","#转换为立体声\n","# ---------------------------- 未执行\n","  # Convert the given audio to the desired number of channels \n","  # ---------------------------- \n","  @staticmethod \n","  def rechannel(aud, new_channel): \n","    sig, sr = aud \n"," \n","    if (sig.shape[0] == new_channel): \n","      # Nothing to do \n","      return aud \n"," \n","    if (new_channel == 1): \n","      # Convert from stereo to mono by selecting only the first channel \n","      resig = sig[:1, :] \n","    else: \n","      # Convert from mono to stereo by duplicating the first channel \n","      resig = torch.cat([sig, sig]) \n"," \n","    return ((resig, sr))\n","\n","#标准化采样率\n","# ---------------------------- \n","  # Since Resample applies to a single channel, we resample one channel at a time \n","  # ---------------------------- \n","  @staticmethod \n","  def resample(aud, newsr): \n","    sig, sr = aud \n"," \n","    if (sr == newsr): \n","      # Nothing to do \n","      return aud \n"," \n","    num_channels = sig.shape[0] \n","    # Resample first channel \n","    resig = torchaudio.transforms.Resample(sr, newsr)(sig[:1,:]) \n","    if (num_channels > 1): \n","      # Resample the second channel and merge both channels \n","      retwo = torchaudio.transforms.Resample(sr, newsr)(sig[1:,:]) \n","      resig = torch.cat([resig, retwo]) \n"," \n","    return ((resig, newsr))\n","\n","#调整为相同长度\n","# ---------------------------- \n","  # Pad (or truncate) the signal to a fixed length 'max_ms' in milliseconds \n","  # ---------------------------- \n","  @staticmethod \n","  def pad_trunc(aud, max_ms): \n","    sig, sr = aud \n","    num_rows, sig_len = sig.shape \n","    max_len = sr//1000 * max_ms \n"," \n","    if (sig_len > max_len): \n","      # Truncate the signal to the given length \n","      sig = sig[:,:max_len] \n"," \n","    elif (sig_len < max_len): \n","      # Length of padding to add at the beginning and end of the signal \n","      pad_begin_len = random.randint(0, max_len - sig_len) \n","      pad_end_len = max_len - sig_len - pad_begin_len \n"," \n","      # Pad with 0s \n","      pad_begin = torch.zeros((num_rows, pad_begin_len)) \n","      pad_end = torch.zeros((num_rows, pad_end_len)) \n"," \n","      sig = torch.cat((pad_begin, sig, pad_end), 1) \n"," \n","    return (sig, sr)\n","\n","#数据扩充增广（时移）\n","# ---------------------------- \n","  # Shifts the signal to the left or right by some percent. Values at the end \n","  # are 'wrapped around' to the start of the transformed signal. \n","  # ---------------------------- \n","  @staticmethod \n","  def time_shift(aud, shift_limit): \n","    sig,sr = aud \n","    _, sig_len = sig.shape \n","    shift_amt = int(random.random() * shift_limit * sig_len) \n","    return (sig.roll(shift_amt), sr)\n","\n","#梅尔谱图\n","# ---------------------------- \n","  # Generate a Spectrogram \n","  # ---------------------------- \n","  @staticmethod \n","  def spectro_gram(aud, n_mels=64, n_fft=1024, hop_len=None): \n","    sig,sr = aud \n","    top_db = 80 \n"," \n","    # spec has shape [channel, n_mels, time], where channel is mono, stereo etc \n","    spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig) \n"," \n","    # Convert to decibels \n","    spec = transforms.AmplitudeToDB(top_db=top_db)(spec) \n","    return (spec)\n","\n","#数据扩充：时间和频率屏蔽\n","# ---------------------------- \n","  # Augment the Spectrogram by masking out some sections of it in both the frequency \n","  # dimension (ie. horizontal bars) and the time dimension (vertical bars) to prevent \n","  # overfitting and to help the model generalise better. The masked sections are \n","  # replaced with the mean value. \n","  # ---------------------------- \n","  @staticmethod \n","  def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1): \n","    _, n_mels, n_steps = spec.shape \n","    mask_value = spec.mean() \n","    aug_spec = spec \n"," \n","    freq_mask_param = max_mask_pct * n_mels \n","    for _ in range(n_freq_masks): \n","      aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value) \n"," \n","    time_mask_param = max_mask_pct * n_steps \n","    for _ in range(n_time_masks): \n","      aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value) \n"," \n","    return aug_spec\n","\n","#自定义数据加载器\n","# from torch.utils.data import DataLoader, Dataset, random_split \n","# import torchaudio \n"," \n","# ---------------------------- \n","# Sound Dataset \n","# ---------------------------- \n","# SoundDS：MyDataset类\n","class SoundDS(Dataset): \n","  def __init__(self, df, data_path): \n","    self.df = df #df为csv文件\n","    self.data_path = str(data_path) \n","    self.duration = 6000 \n","    self.sr = 22050 #采样率\n","    self.channel = 2 #通道数\n","    self.shift_pct = 0.4        \n"," \n","  # ---------------------------- \n","  # Number of items in dataset \n","  # ---------------------------- \n","  def __len__(self): \n","    return len(self.df)     \n"," \n","  # ---------------------------- \n","  # Get i'th item in dataset \n","  # ---------------------------- \n","  def __getitem__(self, idx): \n","    # Absolute file path of the audio file - concatenate the audio directory with \n","    # the relative path \n","    audio_file = self.data_path + self.df.loc[idx, 'relative_path']  #.loc:取idx对应行的所有数据，.loc[idx, 'relative_path']:取idx对应行的relative_path\n","    # Get the Class ID \n","    class_id = self.df.loc[idx, 'classID'] #取idx对应行的classID\n"," \n","    aud = AudioUtil.open(audio_file) \n","    # 有些声音有更高的采样率，或者比大多数声音更少的通道。所以让所有声音都有相同数量的通道和相同的采样率。除非采样速率相同，否则pad_trunc仍然会产生不同长度的数组，即使声音持续时间相同。\n","    reaud = AudioUtil.resample(aud, self.sr) #标准化采样率\n","    rechan = AudioUtil.rechannel(reaud, self.channel) #转换为立体声，统一为两个声道\n"," \n","    dur_aud = AudioUtil.pad_trunc(rechan, self.duration) #调整为相同长度\n","    shift_aud = AudioUtil.time_shift(dur_aud, self.shift_pct) #时移\n","    sgram = AudioUtil.spectro_gram(shift_aud, n_mels=64, n_fft=1024, hop_len=None) #转换为mel谱图\n","    aug_sgram = AudioUtil.spectro_augment(sgram, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2) #时间和频率屏蔽\n"," \n","    return aug_sgram, class_id\n","\n","#使用数据加载器准备一批数据\n","from torch.utils.data import random_split \n"," \n","myds = SoundDS(df,download_path) \n"," \n","# Random split of 90:10 between training and validation \n","num_items = len(myds) \n","num_train = round(num_items * 0.9) \n","num_val = num_items - num_train \n","train_ds, val_ds = random_split(myds, [num_train, num_val]) \n"," \n","# Create training and validation data loaders \n","train_dl = torch.utils.data.DataLoader(train_ds, batch_size=64, shuffle=True) \n","val_dl = torch.utils.data.DataLoader(val_ds, batch_size=64, shuffle=False)\n","\n","#建立模型\n","# import torch.nn.functional as F \n","# from torch.nn import init \n"," \n","# ---------------------------- \n","# Audio Classification Model \n","# ---------------------------- \n","class AudioClassifier (nn.Module): \n","    # ---------------------------- \n","    # Build the model architecture \n","    # ---------------------------- \n","    def __init__(self): \n","        super().__init__() \n","        conv_layers = [] \n"," \n","        # First Convolution Block with Relu and Batch Norm. Use Kaiming Initialization \n","        self.conv1 = nn.Conv2d(2, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2)) #in_channels=2,out_channels=8\n","        self.relu1 = nn.ReLU() \n","        self.bn1 = nn.BatchNorm2d(8) \n","        init.kaiming_normal_(self.conv1.weight, a=0.1) #a-此层之后使用的整流器的负斜率(仅与 'leaky_relu' 一起使用)\n","        self.conv1.bias.data.zero_() \n","        conv_layers += [self.conv1, self.relu1, self.bn1] \n"," \n","        # Second Convolution Block \n","        self.conv2 = nn.Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)) \n","        self.relu2 = nn.ReLU() \n","        self.bn2 = nn.BatchNorm2d(16) \n","        init.kaiming_normal_(self.conv2.weight, a=0.1) \n","        self.conv2.bias.data.zero_() \n","        conv_layers += [self.conv2, self.relu2, self.bn2] \n"," \n","        # third Convolution Block \n","        self.conv3 = nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)) \n","        self.relu3 = nn.ReLU() \n","        self.bn3 = nn.BatchNorm2d(32) \n","        init.kaiming_normal_(self.conv3.weight, a=0.1) \n","        self.conv3.bias.data.zero_() \n","        conv_layers += [self.conv3, self.relu3, self.bn3] \n"," \n","        # fourth Convolution Block \n","        self.conv4 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)) \n","        self.relu4 = nn.ReLU() \n","        self.bn4 = nn.BatchNorm2d(64) \n","        init.kaiming_normal_(self.conv4.weight, a=0.1) \n","        self.conv4.bias.data.zero_() \n","        conv_layers += [self.conv4, self.relu4, self.bn4] \n"," \n","        # Linear Classifier \n","        self.ap = nn.AdaptiveAvgPool2d(output_size=1) \n","        self.lin = nn.Linear(in_features=64, out_features=6) \n"," \n","        # Wrap the Convolutional Blocks 打包卷积块\n","        self.conv = nn.Sequential(*conv_layers) \n"," \n","    # ---------------------------- \n","    # Forward pass computations \n","    # ---------------------------- \n","    def forward(self, x): \n","        # Run the convolutional blocks \n","        x = self.conv(x) \n"," \n","        # Adaptive pool and flatten for input to linear layer \n","        x = self.ap(x) \n","        x = x.view(x.shape[0], -1) #=reshape 重新定义矩阵形状，-1代表动态调整这个维度上的元素个数，以保证元素的总数不变\n"," \n","        # Linear layer \n","        x = self.lin(x) \n"," \n","        # Final output \n","        return x \n"," \n","# Create the model and put it on the GPU if available \n","myModel = AudioClassifier() \n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n","myModel = myModel.to(device) \n","# Check that it is on Cuda \n","next(myModel.parameters()).device\n","\n","#训练\n","# ---------------------------- \n","# Training Loop \n","# ---------------------------- \n","def training(model, train_dl, num_epochs): \n","  # Loss Function, Optimizer and Scheduler \n","  criterion = nn.CrossEntropyLoss() \n","  optimizer = torch.optim.Adam(model.parameters(),lr=0.001) \n","  scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001, \n","                                                steps_per_epoch=int(len(train_dl)), \n","                                                epochs=num_epochs, \n","                                                anneal_strategy='linear') #退火策略，'cos'和'liner'分别表示余弦退火和线性退火\n"," \n","  expdir = Path.cwd()/'/content/drive/MyDrive/hj_data/experiments'\n","  version = 'v1'\n","  logfilepath = expdir / version / 'logs_{}.txt'.format(version)\n","  logfilepath_eval = expdir / version / 'logs_eval_{}.txt'.format(version)\n","  model_savedir = expdir / version \n","  def init_logger(self):\n","        self.logFileName = str(self.logfilepath)\n","        if self.logfilepath.exists == True:\n","            self.logfilepath.exists.unlink()  ## 删除已经存在的log文件 (方便重启实验)\n","        if self.logfilepath_eval.exists == True:\n","            self.logfilepath_eval.exists.unlink()  ## 删除已经存在的log文件 (方便重启实验)\n","        self.logFileName_eval = str(self.logfilepath_eval)\n","\n","        ## 存储training log文件\n","        with open(self.logFileName, 'a', encoding='utf-8') as wf:\n","            # #将参数类中的所有参数写入log\n","            # for k, v in self.hp.__dict__.items():\n","            #     wf.write(\"{} : {}\\n\".format(k, v))\n","            # wf.write('-' * 50 + \"Experiment & Hparams Created\" + \"-\" * 50 + \"\\n\")\n","            wf.write(\"*\" * 100 + \"\\n\")\n","            wf.close()\n","\n","    ## 该方法将一个字典  ，按kv的顺序，写入一行到 log.txt\n","  def write_line2log(log_dict: dict, filedir, isprint: True):\n","      strp = ''\n","      with open(filedir, 'a', encoding='utf-8') as f:\n","          for key, value in log_dict.items():\n","              witem = '{}'.format(key) + ':{},'.format(value)\n","              strp += witem\n","          f.write(strp)\n","          #f.write('当前进程的内存使用：%.4f GB' % (psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024 / 1024))\n","          f.write('\\n')\n","      if isprint:\n","          print(strp)\n","      pass\n","\n","  def print_network(model, name):\n","      \"\"\"Print out the network information.\"\"\"\n","      num_params = 0\n","      for p in model.parameters():\n","          num_params += p.numel()\n","      print(\"Model {},the number of parameters: {}\".format(name, num_params))\n","\n","  #保存模型\n","  def save_model(i):\n","      pdict = {\"model\":model.state_dict(),\n","                }\n","      path = model_savedir / \"{:04}.pth\".format(i)\n","      torch.save(pdict, str(path))\n","      print(\"---------------- model saved ------------------- \")\n","  \n","  def micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on binary arrays.\n","\n","    Args:\n","        preds (list of lists of ints): Predictions.\n","        truths (list of lists of ints): Ground truths.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    # Micro : aggregating over all instances\n","    # device = torch.device('cpu')\n","    # # preds = preds.to(device)\n","    # # truths = preds.to(device)\n","    # preds.cpu()\n","    # truths.cpu()\n","    preds = np.concatenate(preds)\n","    truths = np.concatenate(truths)\n","    return f1_score(truths, preds,average='micro')\n","\n","  #测试\n","  def test_acc (model, val_dl):\n","    correct_prediction = 0\n","    total_prediction = 0\n","\n","    truths = []\n","    preds = []\n","    # Disable gradient updates\n","    with torch.no_grad():\n","      for data in val_dl:\n","        # Get the input features and target labels, and put them on the GPU\n","        inputs, labels = data[0].to(device), data[1].to(device)\n","\n","        # Normalize the inputs\n","        inputs_m, inputs_s = inputs.mean(), inputs.std()\n","        inputs = (inputs - inputs_m) / inputs_s\n","\n","        # Get predictions\n","        outputs = model(inputs)\n","\n","        # Get the predicted class with the highest score\n","        _, prediction = torch.max(outputs,1)\n","        # Count of predictions that matched the target label\n","        correct_prediction += (prediction == labels).sum().item()\n","        total_prediction += prediction.shape[0]\n","        print(f'labes: {labels},preds: {prediction}')\n","        # state = torch.device('cpu')\n","        # labels = labels.to(device)\n","        # prediction = prediction.to(device)\n","        labels = labels.cpu()\n","        prediction = prediction.cpu()\n","        print(f'labes: {labels},preds: {prediction}')\n","        truths.append(labels)\n","        preds.append(prediction)\n","\n","    \n","    acc = correct_prediction/total_prediction\n","    f1 = micro_f1(truths,preds)\n","    losse_curves  = {\"eval_step--\":\"\",\n","                    \"Epoch\":epoch,\n","                    \"Accuracy\":acc,\n","                    \"Micro_f1\":f1,\n","                    \"Total items\":total_prediction}\n","    write_line2log(losse_curves, logfilepath_eval, isprint=True)\n","\n","\n","  # Repeat for each epoch \n","  for epoch in range(1,num_epochs): \n","    running_loss = 0.0 \n","    correct_prediction = 0 \n","    total_prediction = 0 \n"," \n","    # Repeat for each batch in the training set \n","    for i, data in enumerate(train_dl): \n","        # Get the input features and target labels, and put them on the GPU \n","        inputs, labels = data[0].to(device), data[1].to(device) \n"," \n","        # Normalize the inputs \n","        inputs_m, inputs_s = inputs.mean(), inputs.std() #标准差\n","        inputs = (inputs - inputs_m) / inputs_s \n"," \n","        # Zero the parameter gradients \n","        optimizer.zero_grad() \n"," \n","        # forward + backward + optimize \n","        outputs = model(inputs) \n","        loss = criterion(outputs, labels) \n","        loss.backward() \n","        optimizer.step() \n","        scheduler.step() \n"," \n","        # Keep stats for Loss and Accuracy \n","        running_loss += loss.item() \n"," \n","        # Get the predicted class with the highest score \n","        _, prediction = torch.max(outputs,1) \n","        # Count of predictions that matched the target label \n","        correct_prediction += (prediction == labels).sum().item() \n","        total_prediction += prediction.shape[0] \n"," \n","        # if i % 10 == 0:    # print every 10 mini-batches \n","        #     print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 10)) \n"," \n","    # Print stats at the end of the epoch \n","    num_batches = len(train_dl)\n","    avg_loss = running_loss / num_batches \n","    acc = correct_prediction/total_prediction \n","    losse_curves  = {\"Epoch\":epoch,\n","                            \"Loss\":avg_loss,\n","                             \"Accuracy\":acc,\n","                             }\n","    if epoch == 1:\n","      print(\"create loss dict\")\n","      loss_log_dict = {}\n","      for k, v in losse_curves.items():\n","        loss_log_dict[k] = []\n","      print(\"loss dict created\")\n","    \n","    for k, v in loss_log_dict.items():\n","      loss_log_dict[k].append(losse_curves[k])  # 把每batch的loss数据加入到 loss curves中\n","    write_line2log(losse_curves, logfilepath, isprint=True)\n","\n","    ## 模型保存\n","    if epoch % 50 == 0:\n","      test_acc(myModel,val_dl)\n","      save_model(epoch)\n","    # print(f'Epoch: {epoch}, Loss: {avg_loss:.2f}, Accuracy: {acc:.2f}') \n"," \n","  print('Finished Training') \n"," \n","num_epochs=251   # Just for demo, adjust this higher. \n","training(myModel, train_dl, num_epochs)"]},{"cell_type":"markdown","metadata":{"id":"lAB-Dr3oe308"},"source":["# **推理**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F0ifLiFae1Sh"},"outputs":[],"source":["import csv #调用数据保存文件\n","import pandas as pd #用于数据输出\n","from pathlib import Path \n","\n","#读取csv文件 \n","test_path = Path.cwd()/'../test' \n","#model_savedir = '/content/drive/MyDrive/hj_data/experiments/v0' \n"," \n","# Read metadata file \n","testdata_file = test_path/'test.csv' \n","tf = pd.read_csv(testdata_file) \n","tf.head() \n"," \n","# Construct file path by concatenating fold and file name \n","tf['relative_path'] = '/' + tf['slice_file_name'].astype(str) \n"," \n","# Take relevant columns \n","tf = tf[['relative_path', 'classID']] \n","tf.head()\n","\n","\n","#加载测试数据\n","testds = SoundDS(tf,test_path) \n","\n","# Create test data loaders \n","test_dl = torch.utils.data.DataLoader(testds, batch_size=1, shuffle=False) \n","\n","# def __getitem__(self, idx):\n","#   id = self.tf['slice_file_name'].astype(str)\n","\n","# ---------------------------- \n","# Inference \n","# ---------------------------- \n","def inference (model, test_dl): \n","  correct_prediction = 0 \n","  total_prediction = 0 \n","\n","  # Disable gradient updates \n","  with torch.no_grad(): \n","    list_classid = []\n","    list1 = []\n","    id = 0\n","    for data in test_dl: \n","      id = id + 1\n","      # Get the input features and target labels, and put them on the GPU \n","      inputs, labels = data[0].to(device), data[1].to(device) \n"," \n","      # Normalize the inputs \n","      inputs_m, inputs_s = inputs.mean(), inputs.std() \n","      inputs = (inputs - inputs_m) / inputs_s \n"," \n","      # Get predictions \n","      outputs = model(inputs) \n"," \n","      # Get the predicted class with the highest score \n","      _, prediction = torch.max(outputs,1) \n","      ClassId = prediction.item() + 1\n","      list_classid.append(ClassId)\n","      # Count of predictions that matched the target label \n","      #correct_prediction += (prediction == labels).sum().item() \n","      #total_prediction += prediction.shape[0] \n","      list1.append(id)\n","      list=[]\n","      list.append(list1)\n","      list.append(list_classid)\n","      #print(list)\n","      column=['id','label'] #列表头名称\n","      test=pd.DataFrame(zip(list1,list_classid),columns=['id','label'])#将数据放进表格\n","      test.to_csv('result.csv') #数据存入csv,存储位置及文件名称\n","      print(f'{data[0]}, ClassId: {ClassId}')\n","\n","\n","\n"," \n","  #acc = correct_prediction/total_prediction \n","  #print(f'Accuracy: {acc:.2f}, Total items: {total_prediction}') \n"," \n","# Run inference on trained model with the validation set\n","i = 100 #用于指定加载哪个模型\n","#model_path = model_savedir / \"{:04}.pth\".format(i)\n","model_path = '/content/drive/MyDrive/hj_data/experiments/v0/0250.pth'\n","model = myModel\n","state = torch.load(model_path)\n","model.load_state_dict(state['model'])\n","inference(model, test_dl)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Untitled2.ipynb","provenance":[],"authorship_tag":"ABX9TyNE6Sof/kApwlDTvNP90PO8"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}